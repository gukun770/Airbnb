{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function as F\n",
    "from airbnbclass import *\n",
    "from airbnb_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "pd.set_option(\"display.max_rows\",999)\n",
    "pd.set_option(\"display.max_columns\",999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170802.csv...\n",
      "reviews20170802.csv (9057, 37)\n",
      "(13831, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20180110.csv...\n",
      "reviews20180110.csv (6506, 37)\n",
      "(20337, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20180304.csv...\n",
      "reviews20180304.csv (4804, 37)\n",
      "(25141, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20171101.csv...\n",
      "reviews20171101.csv (8929, 37)\n",
      "(34070, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20180202.csv...\n",
      "reviews20180202.csv (4727, 37)\n",
      "(38797, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20180406.csv...\n",
      "reviews20180406.csv (4844, 37)\n",
      "(43641, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20171202.csv...\n",
      "reviews20171202.csv (6940, 37)\n",
      "(50581, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170902.csv...\n",
      "reviews20170902.csv (8529, 37)\n",
      "(59110, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20171002.csv...\n",
      "reviews20171002.csv (8933, 37)\n",
      "(68043, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170502.csv...\n",
      "reviews20170502.csv (8770, 37)\n",
      "(76813, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170702.csv...\n",
      "reviews20170702.csv (8855, 37)\n",
      "(85668, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170101.csv...\n",
      "reviews20170101.csv (9035, 37)\n",
      "(94703, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170302.csv...\n",
      "reviews20170302.csv (8720, 37)\n",
      "(103423, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170602.csv...\n",
      "reviews20170602.csv (8799, 37)\n",
      "(112222, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170402.csv...\n",
      "reviews20170402.csv (8706, 37)\n",
      "(120928, 37)\n",
      "Reading: /Users/Alex/Documents/10_galvanize/galvanize/capstone/dsi-project-proposals/project/data/listings20170202.csv...\n",
      "reviews20170202.csv (8777, 37)\n",
      "(129705, 37)\n"
     ]
    }
   ],
   "source": [
    "sf = Airbnb()\n",
    "columns = ['id','price','availability_30','availability_60','reviews_per_month',\n",
    "'number_of_reviews','last_review','host_since','minimum_nights',\n",
    "'room_type','host_response_time', 'host_is_superhost',\n",
    "'review_scores_rating','property_type', \n",
    "'neighbourhood_cleansed','bedrooms',\n",
    "'calculated_host_listings_count','host_identity_verified',\n",
    "'cleaning_fee','last_scraped','latitude','longitude','beds',\n",
    "'cancellation_policy','access','description','notes','transit',\n",
    "'instant_bookable','extra_people','maximum_nights','house_rules',\n",
    "#            'calendar_updated',\n",
    "]\n",
    "listings = sf.load_data(columns_used=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'last_scraped', 'description', 'notes', 'transit', 'access',\n",
       "       'house_rules', 'host_since', 'host_response_time', 'host_is_superhost',\n",
       "       'host_identity_verified', 'neighbourhood_cleansed', 'latitude',\n",
       "       'longitude', 'property_type', 'room_type', 'bedrooms', 'beds', 'price',\n",
       "       'cleaning_fee', 'extra_people', 'minimum_nights', 'maximum_nights',\n",
       "       'availability_30', 'availability_60', 'number_of_reviews',\n",
       "       'last_review', 'review_scores_rating', 'instant_bookable',\n",
       "       'cancellation_policy', 'calculated_host_listings_count',\n",
       "       'reviews_per_month', 'last30', 'last60', 'last90', 'last120',\n",
       "       'last180'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter 1: 12226, i.e. 9.43% listings removed.\n",
      "\n",
      "FIlter 2 : 22401, i.e.17.27% listings removed.\n",
      "\n",
      "35217 of listings to check\n",
      "Remove 34320 listings. 97.45% of listings checked.  \n",
      "\n",
      "3192 of listings to check\n",
      "Remove 2573 listings. 80.61% of listings checked.  \n",
      "\n",
      "3243 of listings to check\n",
      "Remove 2282 listings. 70.37% of listings checked.  \n",
      "\n",
      "3315 of listings to check\n",
      "Remove 2135 listings. 64.40% of listings checked.  \n",
      "\n",
      "3277 of listings to check\n",
      "Remove 2137 listings. 65.21% of listings checked.  \n",
      "\n",
      "3105 of listings to check\n",
      "Remove 1713 listings. 55.17% of listings checked.  \n",
      "\n",
      "2926 of listings to check\n",
      "Remove 1443 listings. 49.32% of listings checked.  \n",
      "\n",
      "2768 of listings to check\n",
      "Remove 1342 listings. 48.48% of listings checked.  \n",
      "\n",
      "2735 of listings to check\n",
      "Remove 1190 listings. 43.51% of listings checked.  \n",
      "\n",
      "2432 of listings to check\n",
      "Remove 786 listings. 32.32% of listings checked.  \n",
      "\n",
      "2223 of listings to check\n",
      "Remove 750 listings. 33.74% of listings checked.  \n",
      "\n",
      "2030 of listings to check\n",
      "Remove 491 listings. 24.19% of listings checked.  \n",
      "\n",
      "1895 of listings to check\n",
      "Remove 344 listings. 18.15% of listings checked.  \n",
      "\n",
      "1939 of listings to check\n",
      "Remove 164 listings. 8.46% of listings checked.  \n",
      "\n",
      "FIlter 3 : 51670, i.e.39.84% listings removed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listings = sf.filter_data(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43408, 37)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('pre_select', PreselectColumns()),\n",
    "    ('clean_data', DataType()),\n",
    "    ('FeatureEnginner', FeatureEnginner()),\n",
    "    ('PricePerBedroom', PricePerBedroom()),\n",
    "    ('DropColumns', DropColumns()),\n",
    "    ('Getdummies', Getdummies()),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "# m = p.fit(X,y)\n",
    "# X_train_post = m.transform(X_train)\n",
    "# X_test_post = m.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"rf__n_estimators\": [50],}\n",
    "#     \"rf__max_depth\": [4,6,8],\n",
    "#     \"rf__max_features\": ['auto', 'sqrt', 'log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.365954069873\n",
      "{'rf__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "X = listings.copy()\n",
    "y = X.pop('availability_30')\n",
    "# X = X.reset_index()\n",
    "\n",
    "cv_cutoff_date = pd.to_datetime('2017-11-01')\n",
    "cv = -1*(listings.last_scraped < cv_cutoff_date).astype(int)\n",
    "cross_val = PredefinedSplit(cv)\n",
    "\n",
    "rmsle_scorer = make_scorer(mean_squared_log_error, greater_is_better=False)\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=cross_val, scoring=rmsle_scorer,verbose=1, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "\n",
    "with open('rf_pipe.pkl','wb') as f:\n",
    "        pickle.dump(grid, f)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = listings.iloc[[22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = y.values\n",
    "k[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_pipe.pkl','wb') as f:\n",
    "        pickle.dump(grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf_pipe.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_scorer = make_scorer(mean_squared_log_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = F.my_train_test_split(listings, '2017-11-01')\n",
    "p = Pipeline([\n",
    "    ('pre_select', PreselectColumns()),\n",
    "    ('clean_data', DataType()),\n",
    "    ('FeatureEnginner', FeatureEnginner()),\n",
    "    ('PricePerBedroom', PricePerBedroom()),\n",
    "    ('DropColumns', DropColumns()),\n",
    "    ('Getdummies', Getdummies()),\n",
    "#     ('rf', RandomForestRegressor())\n",
    "])\n",
    "mod = p.fit(X_train,y_train)\n",
    "X_train_post = mod.transform(X_train)\n",
    "X_test_post = mod.transform(X_test)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train_post,y_train)\n",
    "\n",
    "\n",
    "y_pred = rf.predict(X_test_post)\n",
    "print(mean_squared_log_error(y_test,y_pred))\n",
    "\n",
    "neg_scorer = lambda y1, y2: mean_squared_log_error(y1, y2)*(-1)\n",
    "feature_importance = F.permutation_importance(rf, X_test_post.values, y_test, scorer=neg_scorer)\n",
    "series_feature_importance = pd.Series(feature_importance,index=X_train_post.columns.tolist())\n",
    "feature_importance = series_feature_importance.copy()\n",
    "\n",
    "F.plot_feature_importance(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselect_cols = list(set([\n",
    "        # 'id',\n",
    "        'price',\n",
    "        'reviews_per_month',\n",
    "        'number_of_reviews',\n",
    "        # 'last_review',\n",
    "        'host_since',\n",
    "        # 'minimum_nights',\n",
    "        'room_type',\n",
    "        'host_response_time',\n",
    "        # 'host_is_superhost',\n",
    "        'review_scores_rating',\n",
    "        'property_type',\n",
    "        'neighbourhood_cleansed',\n",
    "        'bedrooms',\n",
    "        # 'calculated_host_listings_count',\n",
    "        # 'host_identity_verified',\n",
    "        'cleaning_fee',\n",
    "        'last_scraped',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        # 'beds',\n",
    "        # 'cancellation_policy',\n",
    "        # 'access',\n",
    "        # 'description',\n",
    "        # 'notes','transit',\n",
    "        'instant_bookable',\n",
    "        'extra_people',\n",
    "        'maximum_nights',\n",
    "        # 'house_rules',\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = X_train.loc[8,preselect_cols].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '44 Tehama St, San Francisco, CA 94105'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"https://maps.googleapis.com/maps/api/geocode/json?address=\"\n",
    "search_query += address + '&key=' + 'keys'\n",
    "\n",
    "#         print(search_query)\n",
    "response = requests.get(search_query)\n",
    "result = json.loads(response.text)\n",
    "\n",
    "\n",
    "latitude = result['results'][0]['geometry']['location']['lat']\n",
    "longitude = result['results'][0]['geometry']['location']['lng']\n",
    "neighbourhood_cleansed = result['results'][0]['address_components'][2]['short_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.7876372\n",
      "-122.3967284\n",
      "South of Market\n"
     ]
    }
   ],
   "source": [
    "print(latitude)\n",
    "print(longitude)\n",
    "print(neighbourhood_cleansed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 8, 7, 7, 52, 46, 353354)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {'bedrooms': {8: 3.0},\n",
    " 'cleaning_fee': {8: '$150.00'},\n",
    " 'extra_people': {8: '$0.00'},\n",
    " 'host_response_time': {8: 'within an hour'},\n",
    " 'host_since': {8: pd.to_datetime('2018-08-01')},\n",
    " 'instant_bookable': {8: 'f'},\n",
    " 'last_scraped': {8: pd.to_datetime('2018-08-06')},\n",
    " 'latitude': {8: latitude},\n",
    " 'longitude': {8: longitude},\n",
    " 'maximum_nights': {8: 1125},\n",
    " 'neighbourhood_cleansed': {8: 'Seacliff'},\n",
    " 'number_of_reviews': {8: number_of_reviews},\n",
    " 'price': {8: '$195.00'},\n",
    " 'property_type': {8: 'Apartment'},\n",
    " 'review_scores_rating': {8: 99.0},\n",
    " 'reviews_per_month': {8: reviews_per_month},\n",
    " 'room_type': {8: 'Entire home/apt'}}\n",
    "new_data = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_since</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>property_type</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>room_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>$150.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>f</td>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>37.787637</td>\n",
       "      <td>-122.396728</td>\n",
       "      <td>1125</td>\n",
       "      <td>Seacliff</td>\n",
       "      <td>0</td>\n",
       "      <td>$195.00</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms cleaning_fee extra_people host_response_time host_since  \\\n",
       "8       3.0      $150.00        $0.00     within an hour 2018-08-01   \n",
       "\n",
       "  instant_bookable last_scraped   latitude   longitude  maximum_nights  \\\n",
       "8                f   2018-08-06  37.787637 -122.396728            1125   \n",
       "\n",
       "  neighbourhood_cleansed  number_of_reviews    price property_type  \\\n",
       "8               Seacliff                  0  $195.00     Apartment   \n",
       "\n",
       "   review_scores_rating  reviews_per_month        room_type  \n",
       "8                  99.0                  0  Entire home/apt  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.32])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('rf_pipe.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month: 1\n",
      "number of reviews cumulated: 0\n",
      "avaialable: [ 17.04]\n",
      "profit [ 1944.] \n",
      "\n",
      "month: 2\n",
      "number of reviews cumulated: 1\n",
      "avaialable: [ 19.86]\n",
      "profit [ 1521.] \n",
      "\n",
      "month: 3\n",
      "number of reviews cumulated: 2\n",
      "avaialable: [ 19.34]\n",
      "profit [ 1599.] \n",
      "\n",
      "month: 4\n",
      "number of reviews cumulated: 4\n",
      "avaialable: [ 17.56]\n",
      "profit [ 1866.] \n",
      "\n",
      "month: 5\n",
      "number of reviews cumulated: 5\n",
      "avaialable: [ 15.28]\n",
      "profit [ 2208.] \n",
      "\n",
      "month: 6\n",
      "number of reviews cumulated: 6\n",
      "avaialable: [ 12.8]\n",
      "profit [ 2580.] \n",
      "\n",
      "month: 7\n",
      "number of reviews cumulated: 8\n",
      "avaialable: [ 11.24]\n",
      "profit [ 2814.] \n",
      "\n",
      "month: 8\n",
      "number of reviews cumulated: 10\n",
      "avaialable: [ 10.2]\n",
      "profit [ 2970.] \n",
      "\n",
      "month: 9\n",
      "number of reviews cumulated: 12\n",
      "avaialable: [ 10.32]\n",
      "profit [ 2952.] \n",
      "\n",
      "month: 10\n",
      "number of reviews cumulated: 14\n",
      "avaialable: [ 8.16]\n",
      "profit [ 3276.] \n",
      "\n",
      "month: 11\n",
      "number of reviews cumulated: 16\n",
      "avaialable: [ 7.28]\n",
      "profit [ 3408.] \n",
      "\n",
      "month: 12\n",
      "number of reviews cumulated: 19\n",
      "avaialable: [ 6.1]\n",
      "profit [ 3585.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_reviews = 0\n",
    "last_scraped = pd.to_datetime('2018-01-01')\n",
    "reviews_per_month=0\n",
    "for month in range(1,13):\n",
    "    new_data = {'bedrooms': {8: 3.0},\n",
    " 'cleaning_fee': {8: '$50.00'},\n",
    " 'extra_people': {8: '$0.00'},\n",
    " 'host_response_time': {8: 'within an hour'},\n",
    " 'host_since': {8: pd.to_datetime('2018-01-01')},\n",
    " 'instant_bookable': {8: 't'},\n",
    " 'last_scraped': {8: last_scraped},\n",
    " 'latitude': {8: latitude},\n",
    " 'longitude': {8: longitude},\n",
    " 'maximum_nights': {8: 1125},\n",
    " 'neighbourhood_cleansed': {8: neighbourhood_cleansed},\n",
    " 'number_of_reviews': {8: number_of_reviews},\n",
    " 'price': {8: '$195.00'},\n",
    " 'property_type': {8: 'Apartment'},\n",
    " 'review_scores_rating': {8: 99.0},\n",
    " 'reviews_per_month': {8: reviews_per_month},\n",
    " 'room_type': {8: 'Entire home/apt'}}\n",
    "    print('month:', month)\n",
    "    new_data = pd.DataFrame(new_data)\n",
    "    result = model.predict(new_data)\n",
    "    print('number of reviews cumulated:', round(number_of_reviews))\n",
    "    last_scraped = pd.to_datetime('2018-08-07') + datetime.timedelta(month*30)\n",
    "    number_of_reviews += (30 - int(result))/5/2\n",
    "    reviews_per_month = number_of_reviews/month\n",
    "    \n",
    "    print('avaialable:',result)\n",
    "    print('profit',(30-result)*150,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
